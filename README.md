# Analyser GPT: A Conversational Data Analyst Agent

![Python](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python)
![AutoGen](https://img.shields.io/badge/AutoGen-Microsoft-orange?style=for-the-badge&logo=microsoft)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-green?style=for-the-badge&logo=openai)
![Docker](https://img.shields.io/badge/Docker-blue?style=for-the-badge&logo=docker)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit)

This project is a sophisticated, multi-agent system designed to make data analysis conversational. Users can upload a CSV file, interact with a simple Streamlit frontend, issue commands in plain English, and receive data visualizations and insights generated by a team of autonomous AI agents. The backend leverages Microsoft's AutoGen framework with a secure, Dockerized code execution environment.

---

## ‚ú® Key Feature: Autonomous Problem-Solving

The most powerful feature of this agent is its ability to **autonomously debug and correct itself**. During a typical run, the agent intelligently navigates and solves a series of real-world challenges without any human intervention:

1.  **Dependency Management:** When the agent first tries to run analysis code, it detects that the necessary Python libraries (like `pandas` and `matplotlib`) are missing in its Docker environment. It automatically generates and executes a `pip install` command to resolve this.
2.  **Runtime Error Debugging:** The agent's code then fails with a `KeyError` because it assumes the flower type column is named 'species' when it is actually 'variety'.
3.  **Intelligent Investigation:** Instead of stopping, the agent writes new code to inspect the dataset's columns (`data.columns`), correctly identifies the 'variety' column, and then rewrites its original analysis script.
4.  **Successful Execution:** Finally, with the correct libraries installed and the right column name identified, the agent successfully executes the code and generates the final data visualization.

This entire self-correction workflow demonstrates a robust, resilient AI system that mimics a real data analyst's problem-solving process.

---

## üèõÔ∏è Project Architecture

This project is built using a modular, multi-agent architecture. The primary components work together to handle user requests, analyze data, and execute code securely.

1.  **Frontend (`streamlit_app.py`):** A user-friendly web interface built with Streamlit that captures the user's CSV file and natural language prompts.
2.  **AutoGen Team (`teams/analyzer_gpt.py`):** The core orchestrator that manages the workflow and facilitates the conversation between the specialized agents.
3.  **Data Analyzer Agent (`agents/Data_analyzer_agent.py`):** The "brains" of the operation. This agent understands the user's request, plans the analysis, and writes the necessary Python code using Pandas and Matplotlib.
4.  **Code Executor Agent (`agents/Code_executor_agent.py`):** This agent receives Python code from the Analyzer. It executes this code in a **secure and isolated Docker container** to generate plots and insights, ensuring no risky code is run on the host machine.

---

## üõ†Ô∏è Technologies Used

* **AI Framework:** Microsoft AutoGen
* **LLM:** OpenAI GPT-4 / gpt-4o
* **Containerization:** Docker
* **Data Science:** Pandas, Matplotlib
* **Web Frontend:** Streamlit
* **Core Language:** Python 3.11+

---

## üöÄ Getting Started

Follow these instructions to get a copy of the project up and running on your local machine.

### Prerequisites

* Python 3.10+
* An OpenAI API Key
* Docker Desktop installed and running on your machine.

### Installation

1.  **Clone the repository:**
    ```sh
    git clone [https://github.com/iharshitmishra/Data-Analyst-Agent-Analyzer-GPT.git](https://github.com/iharshitmishra/Data-Analyst-Agent-Analyzer-GPT.git)
    cd Data-Analyst-Agent-Analyzer-GPT
    ```
2.  **Install the required packages:**
    ```sh
    pip install -r requirements.txt
    ```
3.  **Set up your environment variables:**
    * Create a file named `.env` in the project's root directory.
    * Add your OpenAI API key to it like this:
        ```env
        OPENAI_API_KEY='sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'
        ```

---

## üí° Usage

To launch the web interface, run the Streamlit app from your terminal:

```sh
streamlit run streamlit_app.py
